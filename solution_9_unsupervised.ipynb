{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solution_library import *\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as plt, pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(29, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    x_df, y_df = claims_preprocess_get_xy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_df.values.astype(np.float64)\n",
    "y = y_df.values.astype(np.float64)\n",
    "\n",
    "scalar = MinMaxScaler() # USE THIS SAME SCALAR LATER\n",
    "x_norm = scalar.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x_norm, y, test_size = 0.15, random_state=0)\n",
    "\n",
    "inputs = torch.from_numpy(x_train)\n",
    "targets = torch.from_numpy(y_train)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([2126])) that is different to the input size (torch.Size([2126, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1. Loss: 1282.689. Validation Loss: 1418.347\n",
      "Epoch:    2. Loss: 900.066. Validation Loss: 1420.313\n",
      "Epoch:    3. Loss: 1265.087. Validation Loss: 1420.427\n",
      "Epoch:    4. Loss: 1416.563. Validation Loss: 1447.503\n",
      "Epoch:    5. Loss: 589.413. Validation Loss: 1417.136\n",
      "Epoch:    6. Loss: 697.050. Validation Loss: 1418.900\n",
      "Epoch:    7. Loss: 1010.062. Validation Loss: 1419.074\n",
      "Epoch:    8. Loss: 1005.585. Validation Loss: 1417.046\n",
      "Epoch:    9. Loss: 1417.960. Validation Loss: 1421.723\n",
      "Epoch:   10. Loss: 963.796. Validation Loss: 1420.586\n",
      "Epoch:   11. Loss: 1256.523. Validation Loss: 1423.004\n",
      "Epoch:   12. Loss: 866.458. Validation Loss: 1417.110\n",
      "Epoch:   13. Loss: 771.442. Validation Loss: 1418.581\n",
      "Epoch:   14. Loss: 1051.459. Validation Loss: 1416.945\n",
      "Epoch:   15. Loss: 1019.094. Validation Loss: 1420.165\n",
      "Epoch:   16. Loss: 771.279. Validation Loss: 1417.636\n",
      "Epoch:   17. Loss: 1242.400. Validation Loss: 1417.257\n",
      "Epoch:   18. Loss: 791.301. Validation Loss: 1417.265\n",
      "Epoch:   19. Loss: 979.071. Validation Loss: 1418.484\n",
      "Epoch:   20. Loss: 993.504. Validation Loss: 1418.935\n",
      "Epoch:   21. Loss: 1629.057. Validation Loss: 1418.097\n",
      "Epoch:   22. Loss: 1341.906. Validation Loss: 1416.924\n",
      "Epoch:   23. Loss: 1201.340. Validation Loss: 1417.387\n",
      "Epoch:   24. Loss: 769.734. Validation Loss: 1423.020\n",
      "Epoch:   25. Loss: 2609.532. Validation Loss: 1417.061\n",
      "Epoch:   26. Loss: 1446.917. Validation Loss: 1420.721\n",
      "Epoch:   27. Loss: 945.445. Validation Loss: 1422.994\n",
      "Epoch:   28. Loss: 4736.024. Validation Loss: 1419.942\n",
      "Epoch:   29. Loss: 946.417. Validation Loss: 1426.904\n",
      "Epoch:   30. Loss: 632.492. Validation Loss: 1417.254\n",
      "Epoch:   31. Loss: 1396.685. Validation Loss: 1422.789\n",
      "Epoch:   32. Loss: 1176.927. Validation Loss: 1420.243\n",
      "Epoch:   33. Loss: 916.922. Validation Loss: 1417.118\n",
      "Epoch:   34. Loss: 1872.193. Validation Loss: 1418.055\n",
      "Epoch:   35. Loss: 648.200. Validation Loss: 1416.920\n",
      "Epoch:   36. Loss: 736.951. Validation Loss: 1419.750\n",
      "Epoch:   37. Loss: 742.849. Validation Loss: 1417.171\n",
      "Epoch:   38. Loss: 1867.377. Validation Loss: 1417.500\n",
      "Epoch:   39. Loss: 1283.633. Validation Loss: 1419.492\n",
      "Epoch:   40. Loss: 1168.156. Validation Loss: 1417.375\n",
      "Epoch:   41. Loss: 1465.841. Validation Loss: 1416.906\n",
      "Epoch:   42. Loss: 834.043. Validation Loss: 1417.912\n",
      "Epoch:   43. Loss: 662.534. Validation Loss: 1420.741\n",
      "Epoch:   44. Loss: 1528.249. Validation Loss: 1428.164\n",
      "Epoch:   45. Loss: 725.173. Validation Loss: 1417.952\n",
      "Epoch:   46. Loss: 1148.667. Validation Loss: 1416.950\n",
      "Epoch:   47. Loss: 654.085. Validation Loss: 1419.044\n",
      "Epoch:   48. Loss: 780.267. Validation Loss: 1420.315\n",
      "Epoch:   49. Loss: 1300.286. Validation Loss: 1418.655\n",
      "Epoch:   50. Loss: 1229.485. Validation Loss: 1418.293\n",
      "Epoch:   51. Loss: 1198.038. Validation Loss: 1417.715\n",
      "Epoch:   52. Loss: 784.121. Validation Loss: 1416.891\n",
      "Epoch:   53. Loss: 2320.049. Validation Loss: 1417.118\n",
      "Epoch:   54. Loss: 1631.035. Validation Loss: 1417.011\n",
      "Epoch:   55. Loss: 713.756. Validation Loss: 1420.176\n",
      "Epoch:   56. Loss: 2033.699. Validation Loss: 1417.303\n",
      "Epoch:   57. Loss: 958.717. Validation Loss: 1417.102\n",
      "Epoch:   58. Loss: 1227.214. Validation Loss: 1418.657\n",
      "Epoch:   59. Loss: 721.386. Validation Loss: 1416.917\n",
      "Epoch:   60. Loss: 994.288. Validation Loss: 1417.862\n",
      "Epoch:   61. Loss: 700.455. Validation Loss: 1418.263\n",
      "Epoch:   62. Loss: 1387.917. Validation Loss: 1417.142\n",
      "Epoch:   63. Loss: 1782.565. Validation Loss: 1417.786\n",
      "Epoch:   64. Loss: 826.233. Validation Loss: 1420.793\n",
      "Epoch:   65. Loss: 828.640. Validation Loss: 1417.976\n",
      "Epoch:   66. Loss: 1063.719. Validation Loss: 1416.888\n",
      "Epoch:   67. Loss: 1689.837. Validation Loss: 1417.248\n",
      "Epoch:   68. Loss: 1263.447. Validation Loss: 1416.952\n",
      "Epoch:   69. Loss: 1038.474. Validation Loss: 1419.440\n",
      "Epoch:   70. Loss: 865.045. Validation Loss: 1417.852\n",
      "Epoch:   71. Loss: 1839.762. Validation Loss: 1425.965\n",
      "Epoch:   72. Loss: 821.710. Validation Loss: 1418.427\n",
      "Epoch:   73. Loss: 1380.141. Validation Loss: 1416.961\n",
      "Epoch:   74. Loss: 717.108. Validation Loss: 1417.343\n",
      "Epoch:   75. Loss: 1192.158. Validation Loss: 1416.895\n",
      "Epoch:   76. Loss: 664.475. Validation Loss: 1416.921\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataset = torch.utils.data.TensorDataset(inputs, targets)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for epoch in range(150):\n",
    "    try:\n",
    "        for inputs_batch, targets_batch in dataloader:\n",
    "            optimizer.zero_grad()  # zero the parameter gradients\n",
    "            outputs = model(inputs_batch)  # forward pass\n",
    "            loss = torch.sqrt(criterion(outputs, targets_batch))  # compute loss\n",
    "            loss.backward()  # backward pass\n",
    "            optimizer.step()  # update weights\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(x_test)\n",
    "            val_loss = torch.sqrt(criterion(val_outputs, y_test))\n",
    "\n",
    "        print(f'Epoch: {epoch + 1:4d}. Loss: {loss.item():.3f}. Validation Loss: {val_loss.item():.3f}')\n",
    "\n",
    "        if loss.item() < 700 and count > 5:\n",
    "            break\n",
    "        elif loss.item() < 700:\n",
    "            count += 1\n",
    "            pass\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Ended Training Early')\n",
    "        break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(9000):\n",
    "#     try:\n",
    "#         outputs = model(inputs) # forward + backward + optimize        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "#         optimizer.zero_grad() # zero the parameter gradients\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         print(f'Epoch: {epoch + 1:4d}. Loss: {loss:.3f}')\n",
    "\n",
    "#         if loss < 1E-7:\n",
    "#             break\n",
    "#             # pass\n",
    "\n",
    "#     except KeyboardInterrupt:\n",
    "#         print('Ended Training Early')\n",
    "#         break\n",
    "\n",
    "\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\solution_library.py:119: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  claims['pol_pay_freq'] = claims['pol_pay_freq'].replace( {'Biannual': 2, 'Yearly': 1, 'Monthly': 12, 'Quarterly': 4} )\n",
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\solution_library.py:120: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  claims['pol_payd'] = claims['pol_payd'].replace( {'No': 0, 'Yes': 1} )\n",
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\solution_library.py:121: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  claims['drv_sex1'] = claims['drv_sex1'].replace( {'M': 1, 'F': 0} )\n",
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\solution_library.py:122: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  claims['vh_type'] = claims['vh_type'].replace( {'Tourism': 1, 'Commercial': 0} )\n",
      "c:\\Users\\kyle\\OneDrive\\Programs\\Cooperators_2024\\solution_library.py:123: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  claims['drv_drv2'] = claims['drv_drv2'].replace( {'No': 0, 'Yes': 1} )\n"
     ]
    }
   ],
   "source": [
    "x_new, ids = preprocess_x(load_tests())\n",
    "\n",
    "x_new = x_new.values.astype(np.float64)\n",
    "\n",
    "x_new_norm = scalar.transform(x_new)\n",
    "\n",
    "inputs_pred = torch.from_numpy(x_new_norm)\n",
    "\n",
    "model.eval() # convert to evaluation mode\n",
    "\n",
    "with torch.no_grad(): # forward pass\n",
    "    predictions = model(inputs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1416.9009)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = RMSE(predictions, y_test)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1132.507558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1122.830905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1143.387248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1126.137521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1136.761373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>1131.069713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>1117.706367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>1134.945978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>1132.106309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>1144.509659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      claim_amount\n",
       "0      1132.507558\n",
       "1      1122.830905\n",
       "2      1143.387248\n",
       "3      1126.137521\n",
       "4      1136.761373\n",
       "...            ...\n",
       "4135   1131.069713\n",
       "4136   1117.706367\n",
       "4137   1134.945978\n",
       "4138   1132.106309\n",
       "4139   1144.509659\n",
       "\n",
       "[4140 rows x 1 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(predictions, columns=['claim_amount'])\n",
    "\n",
    "save_data = pd.concat([ids, predictions], axis = 1)\n",
    "\n",
    "save_data.to_csv(f'predictions/pred_nn_v1')\n",
    "\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
